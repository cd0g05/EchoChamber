# class ReadPage:
#
#     def get_cnn_headlines(self):
#         title_classes = ["container__headline-text"]
#         doc = page.get_html("https://www.cnn.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_fox_headlines(self):
#         title_classes = ["title"]
#         doc = page.get_html("https://www.foxnews.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_nyt_headlines(self):
#         title_classes = ["css-xdandi","indicate-hover css-1gg6cw2","indicate-hover css-91bpc3", "indicate-hover css-11gjfuy", "indicate-hover css-1a5fuvt"]
#         doc = page.get_html("https://www.nytimes.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_nbc_headlines(self):
#         title_classes = ["storyline__headline founders-cond fw6 large","related-content-tease__headline-link", "multistoryline__headline founders-cond fw6 large noBottomSpace"]
#         doc = page.get_html("https://www.nbcnews.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_oann_headlines(self):
#         title_classes = ["slider-title","entry-title"]
#         doc = page.get_html("https://www.oann.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_npr_headlines(self):
#         title_classes = ["title"]
#         doc = page.get_html("https://www.npr.org")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_politico_headlines(self):
#         options = Options()
#         options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36")
#         options.add_argument("--headless=new")
#
#         service = Service(ChromeDriverManager().install())  # Auto-downloads ChromeDriver if needed
#         driver = webdriver.Chrome(service=service, options=options)
#
#         driver.set_page_load_timeout(20)  # Timeout if it takes too long
#         try:
#             driver.get("https://www.politico.com")
#             driver.implicitly_wait(2)
#             doc = BeautifulSoup(driver.page_source, "html.parser")
#             title_classes = ["headline is-standard-typeface", "headline  is-alternate-typeface", "headline track-visited", "media-item__title", "js-tealium-tracking"]
#             hl_tags = []
#             for class_name in title_classes:
#                 hl_tags.extend(doc.find_all(True, class_=class_name))
#             # hl_tags = doc.find_all("title")
#             return hl_tags
#         except Exception as e:
#             print(f"Error loading Politico: {e}")
#         finally:
#             driver.quit()
#
#     def get_ap_headlines(self):
#         title_classes = ["PagePromoContentIcons-text"]
#         doc = page.get_html("https://apnews.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_newsmax_headlines(self):
#         title_classes = ["Default", "nmNewsfrontHeadLink Default", "css1"]
#         doc = page.get_html("https://www.newsmax.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_dailywire_headlines(self):
#         title_classes = ["Homepage_topStoryTitle__vxI_h", "allPosts_textContainer__KAL9G"] #allPosts_post__BjxZb
#         doc = page.get_html("https://www.dailywire.com")
#         hl_tags = []
#         hl_tags.extend(doc.find_all(True, class_="Homepage_topStoryTitle__vxI_h"))
#         hl_tags.extend(doc.find_all(True, class_="allPosts_textContainer__KAL9G"))
#         return hl_tags
#
#     def get_washtimes_headlines(self):
#         title_classes = ["article-headline"]
#         doc = page.get_html("https://www.washingtontimes.com")
#         return page.extract_headlines(title_classes, doc)
#
#     def get_washpost_headlines(self):
#         title_classes = ["headline relative gray-darkest pb-xs", "wpds-c-iiQaMf wpds-c-iiQaMf-ihMULTC-css"]
#         doc = page.get_html("https://www.washingtonpost.com")
#         return page.extract_headlines(title_classes, doc)
#
#     # def get_wsj_headlines(self):
#     #     # title_classes = ["HeadlineTextBlock"] #, "e1sf124z8 css-1lys499-HeadlineTextBlock", "e1sf124z8 css-dne82r-HeadlineTextBlock", "e1sf124z8 css-b4ychf-HeadlineTextBlock", "e1sf124z8 css-1qw2665-HeadlineTextBlock"
#     #     # doc = page.get_html("https://www.wsj.com")
#     #     # hl_tags = []
#     #     # hl_tags.extend(doc.find_all(True, class_=re.compile(r"HeadlineTextBlock")))
#     #     # return hl_tags
#     #     options = webdriver.ChromeOptions()
#     #     options.add_argument("--headless")  # Run in headless mode (no UI)
#     #     options.add_argument("--no-sandbox")
#     #     options.add_argument("--disable-dev-shm-usage")
#     #     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
#     #
#     #     driver = webdriver.Chrome(options=options)
#     #     url = "https://www.wsj.com"
#     #     driver.get(url)
#     #     for _ in range(5):
#     #         driver.execute_script("window.scrollBy(0, 1000);")
#     #         time.sleep(2)
#     #     WebDriverWait(driver, 10).until(
#     #         EC.presence_of_element_located((By.XPATH, "//*[contains(@class, 'HeadlineTextBlock')]"))
#     #     )
#     #     elements = driver.find_elements(By.XPATH, "//*[contains(@class, 'HeadlineTextBlock')]")
#     #     driver.quit()
#     #     return elements
#     #
#     # def get_nyp_headlines(self):
#     #     options = Options()
#     #     options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36")
#     #     options.add_argument("--headless=new")
#     #
#     #     service = Service(ChromeDriverManager().install())  # Auto-downloads ChromeDriver if needed
#     #     driver = webdriver.Chrome(service=service, options=options)
#     #
#     #     driver.set_page_load_timeout(20)  # Timeout if it takes too long
#     #     try:
#     #         driver.get("https://nypost.com")
#     #         driver.implicitly_wait(5)
#     #         doc = BeautifulSoup(driver.page_source, "html.parser")
#     #         title_classes = ["story__headline headline headline--xl","story__headline headline headline--sm", "story__headline headline headline--xxs"]
#     #         hl_tags = []
#     #         for class_name in title_classes:
#     #             hl_tags.extend(doc.find_all(True, class_=class_name))
#     #         # hl_tags = doc.find_all("title")
#     #         return hl_tags
#     #     except Exception as e:
#     #         print(f"Error loading NYP: {e}")
#     #     finally:
#     #         driver.quit()
#
#
#     def get_html(self, url:str):
#         headers = {
#             "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/537.36"
#         }
#         result = requests.get(url, headers=headers)
#         return BeautifulSoup(result.text, "html.parser")
#
#     def extract_headlines(self, html, doc):
#         hl_tags = []
#         for class_name in html:
#             hl_tags.extend(doc.find_all(True, class_=class_name))
#         return hl_tags
#
#
#     def compile_headlines(self):
#         # nyp = page.get_nyp_headlines()
#         #page.get_wsj_headlines()
#
#         news_sources = [
#             page.get_cnn_headlines(),
#             page.get_nyt_headlines(),
#             page.get_nbc_headlines(),
#             page.get_fox_headlines(),
#             page.get_oann_headlines(),
#             page.get_npr_headlines(),
#             # page.get_politico_headlines(),
#             page.get_ap_headlines(),
#             page.get_newsmax_headlines(),
#             page.get_dailywire_headlines(),
#             page.get_washtimes_headlines()
#         ] #, npy
#         # news_sources[3] = [headline for i, headline in enumerate(news_sources[3]) if i not in [0, 2, 4]]
#         return news_sources
#
#     def write_hl_to_file(self, flag:str, url:str, news_sources, names, timestamp):
#             with open(url, flag) as file:
#                 news_src = 0
#                 if (flag == 'a'):
#                     file.write(f"\n+++++++++++++++++++++\nDate: {timestamp}\n")
#                 for source in news_sources:
#                     count = 0
#                     file.write(f"\n{names[news_src]}\n--------------------\n")
#                     for headline in source:
#                         if count > 20:
#                             break
#                         text = headline.get_text(strip=True)
#                         if 30 < len(text) < 120:
#                             file.write(text)
#                             file.write(f"\n")
#                             count += 1
#                     news_src += 1
#
#     def run_prog(self, hls):
#         names =  ["CNN", "New York Times", "NBC", "FOX", "OANN", "NPR", "AP", "Newsmax", "Dailywire", "Washington Times"] #, "New York Post" , "Politico" , "Wall Street Journal"
#         now = datetime.now()
#         timestamp = now.strftime("%Y-%m-%d %H:%M:%S")  # Format: YYYY-MM-DD HH:MM:SS
#         page.write_hl_to_file('a', '/Users/cartercripe/dev/code/projects/EchoChamber/src/allHeadlines.txt', hls, names, timestamp)
#         page.write_hl_to_file('w', '/Users/cartercripe/dev/code/projects/EchoChamber/src/daysHeadlines.txt', hls, names, timestamp)

# from openai import OpenAI
# client = OpenAI()
# OpenAI.api_key = ""
#
# class headlineAnalysis:
#
#     def readLines(self, url:str):
#         with open(url, "r", encoding="utf-8") as file:
#             lines = file.read()
#         return lines
#
#     def translate_into_tags(self) -> str:
#         response = client.chat.completions.create(
#             model="gpt-4o-mini",
#             messages=[
#                 {"role": "system", "content": "Your purpose is to analyze news headlines. You are given text containing 20 news headlines from each source. You are to replace each headlines with tags describing the headline. First, decide on several broad categories based on all the headlines, and then assign a category tag to each headline based on which category it best fits into. Then for each headline, assign several descriptive tags to the headline. For example, given the headline 'Donald Trump announces new Tarrif on mexico that would cripple the US Economy', it might translate to 'Category: <Tarrifs>, Tags: <Negative><Economy><Politics><Anti-Trump>'"},
#                 {"role": "user", "content": headlineAnalysis.readLines("/Users/cartercripe/dev/code/projects/EchoChamber/src/oldDaysHeadlines.txt")}
#             ]
#         )
#         return response.choices[0].message.content